{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy and score a machine learning model by using an online endpoint \n",
    "\n",
    "Learn how to use an online endpoint to deploy your model, so you don't have to create and manage the underlying infrastructure. You'll begin by deploying a model on your local machine to debug any errors, and then you'll deploy and test it in Azure.\n",
    "\n",
    "Managed online endpoints help to deploy your ML models in a turnkey manner. Managed online endpoints work with powerful CPU and GPU machines in Azure in a scalable, fully managed way. Managed online endpoints take care of serving, scaling, securing, and monitoring your models, freeing you from the overhead of setting up and managing the underlying infrastructure. \n",
    "\n",
    "For more information, see [What are Azure Machine Learning endpoints?](https://docs.microsoft.com/azure/machine-learning/concept-endpoints)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "* Setup Azure Machine Learning Studio\n",
    "\n",
    "* Install and configure the [Python SDK v2](sdk/setup.sh).\n",
    "\n",
    "* You must have an Azure resource group, and you (or the service principal you use) must have Contributor access to it.\n",
    "\n",
    "* You must have an Azure Machine Learning workspace. \n",
    "\n",
    "* To deploy locally, you must install Docker Engine on your local computer. We highly recommend this option, so it's easier to debug issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-ai-ml\n",
      "  Downloading azure_ai_ml-1.2.0-py3-none-any.whl (4.0 MB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.3.0\n",
      "  Downloading azure_mgmt_core-1.3.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from azure-ai-ml) (6.0)\n",
      "Collecting azure-storage-file-share<13.0.0\n",
      "  Downloading azure_storage_file_share-12.10.1-py3-none-any.whl (252 kB)\n",
      "Requirement already satisfied: colorama<0.5.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from azure-ai-ml) (0.4.4)\n",
      "Collecting opencensus-ext-azure<2.0.0\n",
      "  Downloading opencensus_ext_azure-1.1.7-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from azure-ai-ml) (4.64.0)\n",
      "Collecting msrest>=0.6.18\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Collecting azure-storage-blob<13.0.0,>=12.10.0\n",
      "  Downloading azure_storage_blob-12.14.1-py3-none-any.whl (383 kB)\n",
      "Collecting azure-storage-file-datalake<13.0.0\n",
      "  Downloading azure_storage_file_datalake-12.9.1-py3-none-any.whl (238 kB)\n",
      "Collecting isodate\n",
      "  Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Collecting pydash<6.0.0\n",
      "  Downloading pydash-5.1.2-py3-none-any.whl (84 kB)\n",
      "Collecting azure-core!=1.22.0,<2.0.0,>=1.8.0\n",
      "  Downloading azure_core-1.26.2-py3-none-any.whl (173 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from azure-ai-ml) (4.1.1)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from azure-ai-ml) (2.1.0)\n",
      "Collecting strictyaml<2.0.0\n",
      "  Downloading strictyaml-1.6.2.tar.gz (130 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.5\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "Collecting azure-common<2.0.0,>=1.1\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from azure-ai-ml) (4.4.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from azure-core!=1.22.0,<2.0.0,>=1.8.0->azure-ai-ml) (2.27.1)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from azure-core!=1.22.0,<2.0.0,>=1.8.0->azure-ai-ml) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (3.4.8)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\moh\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (2.21)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (21.4.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.5->azure-ai-ml) (21.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from msrest>=0.6.18->azure-ai-ml) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from msrest>=0.6.18->azure-ai-ml) (2021.10.8)\n",
      "Collecting opencensus<1.0.0,>=0.11.0\n",
      "  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\n",
      "Collecting azure-identity<2.0.0,>=1.5.0\n",
      "  Downloading azure_identity-1.12.0-py3-none-any.whl (135 kB)\n",
      "Requirement already satisfied: psutil>=5.6.3 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (5.8.0)\n",
      "Collecting msal<2.0.0,>=1.12.0\n",
      "  Downloading msal-1.20.0-py2.py3-none-any.whl (90 kB)\n",
      "Collecting msal-extensions<2.0.0,>=0.3.0\n",
      "  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting portalocker<3,>=1.6\n",
      "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting opencensus-context>=0.1.3\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.25.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\moh\\anaconda3\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (2021.3)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (61.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.53.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.33.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (3.19.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (4.7.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.5->azure-ai-ml) (3.0.4)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from portalocker<3,>=1.6->msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (305)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core!=1.22.0,<2.0.0,>=1.8.0->azure-ai-ml) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core!=1.22.0,<2.0.0,>=1.8.0->azure-ai-ml) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from requests>=2.18.4->azure-core!=1.22.0,<2.0.0,>=1.8.0->azure-ai-ml) (1.26.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in c:\\users\\moh\\anaconda3\\lib\\site-packages (from strictyaml<2.0.0->azure-ai-ml) (2.8.2)\n",
      "Building wheels for collected packages: strictyaml\n",
      "  Building wheel for strictyaml (setup.py): started\n",
      "  Building wheel for strictyaml (setup.py): finished with status 'done'\n",
      "  Created wheel for strictyaml: filename=strictyaml-1.6.2-py3-none-any.whl size=123940 sha256=56742ae4b5be7730fb55498aef98ce6efd0d37f797f076dce1b0b2ef0ff36bdc\n",
      "  Stored in directory: c:\\users\\moh\\appdata\\local\\pip\\cache\\wheels\\2a\\59\\c1\\82ec8da49fe5abc15183319250589e7a0efe43ed02b1e6c555\n",
      "Successfully built strictyaml\n",
      "Installing collected packages: portalocker, msal, isodate, azure-core, opencensus-context, msrest, msal-extensions, opencensus, azure-storage-blob, azure-identity, strictyaml, pydash, opencensus-ext-azure, marshmallow, azure-storage-file-share, azure-storage-file-datalake, azure-mgmt-core, azure-common, azure-ai-ml\n",
      "Successfully installed azure-ai-ml-1.2.0 azure-common-1.1.28 azure-core-1.26.2 azure-identity-1.12.0 azure-mgmt-core-1.3.2 azure-storage-blob-12.14.1 azure-storage-file-datalake-12.9.1 azure-storage-file-share-12.10.1 isodate-0.6.1 marshmallow-3.19.0 msal-1.20.0 msal-extensions-1.0.0 msrest-0.7.1 opencensus-0.11.0 opencensus-context-0.1.3 opencensus-ext-azure-1.1.7 portalocker-2.6.0 pydash-5.1.2 strictyaml-1.6.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-ai-ml\n",
    "%pip install docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity import InteractiveBrowserCredential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [default azure authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for this tutorial. Check the [configuration notebook](../../jobs/configuration.ipynb) for more details on how to configure credentials and connect to a workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter details of your AML workspace\n",
    "subscription_id = \"73fc0666-cbe3-4535-b3c6-83baeeaf94f5\"\n",
    "resource_group = \"fhtw-solution-engineering\"\n",
    "workspace = \"fhtw-ml-23\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: .\\config.json\n"
     ]
    }
   ],
   "source": [
    "# get a handle to the workspace\n",
    "credential = InteractiveBrowserCredential(tenant_id=\"a0a6d112-ab35-410a-b961-1280cf758bfc\")\n",
    "ml_client = MLClient.from_config(credential=credential)\n",
    "# ml_client =\n",
    "# MLClient(\n",
    "#      DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy and debug locally by using local endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "* To deploy locally, [Docker Engine](https://docs.docker.com/engine/install/) must be installed.\n",
    "* Docker Engine must be running. Docker Engine typically starts when the computer starts. If it doesn't, you can [troubleshoot Docker Engine](https://docs.docker.com/config/daemon/#start-the-daemon-manually)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create local endpoint and deployment\n",
    "\n",
    "## 2.1 Create local endpoint\n",
    "\n",
    "The goal of a local endpoint deployment is to validate and debug your code and configuration before you deploy to Azure. Local deployment has the following limitations:\n",
    "* Local endpoints *do not support* traffic rules, authentication, or probe settings.\n",
    "* Local endpoints support only one deployment per endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a local endpoint\n",
    "import datetime\n",
    "\n",
    "local_endpoint_name = \"local-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=local_endpoint_name, description=\"this is a sample local endpoint\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating local endpoint (local-01090227674432) Done (0m 0s)\n",
      "Field 'mirror_traffic': This is an experimental field, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': None, 'scoring_uri': None, 'openapi_uri': None, 'name': 'local-01090227674432', 'description': 'this is a sample local endpoint', 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/home/codespace/.azureml/inferencing/local-01090227674432'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fae2f388c10>, 'auth_mode': 'key', 'location': None, 'identity': None, 'traffic': {}, 'mirror_traffic': {}, 'kind': None})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Create local deployment\n",
    "\n",
    "The example contains all the files needed to deploy a model on an online endpoint. To deploy a model, you must have:\n",
    "\n",
    "* Model files (or the name and version of a model that's already registered in your workspace). In the example, we have a scikit-learn model that does regression.\n",
    "* The code that's required to score the model. In this case, we have a score.py file.\n",
    "* An environment in which your model runs. As you'll see, the environment might be a Docker image with Conda dependencies, or it might be a Dockerfile.\n",
    "* Settings to specify the instance type and scaling capacity.\n",
    "\n",
    "### Key aspects of deployment \n",
    "\n",
    "- `name` - Name of the deployment.\n",
    "- `endpoint_name` - Name of the endpoint to create the deployment under.\n",
    "- `model` - The model to use for the deployment. This value can be either a reference to an existing versioned model in the workspace or an inline model specification.\n",
    "- `environment` - The environment to use for the deployment. This value can be either a reference to an existing versioned environment in the workspace or an inline environment specification.\n",
    "- `code_configuration` - the configuration for the source code and scoring script\n",
    "    - `path`- Path to the source code directory for scoring the model\n",
    "    - `scoring_script` - Relative path to the scoring file in the source code directory\n",
    "- `instance_type` - The VM size to use for the deployment. For the list of supported sizes, see [Managed online endpoints SKU list](https://docs.microsoft.com/en-us/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list).\n",
    "- `instance_count` - The number of instances to use for the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(path=\"regression_model.pkl\")\n",
    "env = Environment(\n",
    "    conda_file=\"./conda.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    ")\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=local_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(code=\"./\", scoring_script=\"score.py\"),\n",
    "    instance_type=\"Standard_DS2_v2\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(\n",
    "    deployment=blue_deployment, local=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Verify the local deployment succeeded\n",
    "\n",
    "## 3.1 Check the status to see whether the model was deployed without error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.get(name=local_endpoint_name, local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Get logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_deployments.get_logs(\n",
    "    name=\"blue\", endpoint_name=local_endpoint_name, local=True, lines=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Invoke the local endpoint\n",
    "Invoke the endpoint to score the model by using the convenience command invoke and passing query parameters that are stored in a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=local_endpoint_name,\n",
    "    request_file=\"../model-1/sample-request.json\",\n",
    "    local=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Deploy your online endpoint to Azure\n",
    "Next, deploy your online endpoint to Azure.\n",
    "\n",
    "## 4.1 Configure online endpoint\n",
    "`endpoint_name`: The name of the endpoint. It must be unique in the Azure region. Naming rules are defined under [managed online endpoint limits](https://docs.microsoft.com/azure/machine-learning/how-to-manage-quotas#azure-machine-learning-managed-online-endpoints-preview).\n",
    "\n",
    "`auth_mode` : Use `key` for key-based authentication. Use `aml_token` for Azure Machine Learning token-based authentication. A `key` does not expire, but `aml_token` does expire. \n",
    "\n",
    "Optionally, you can add description, tags to your endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a unique endpoint name with current datetime to avoid conflicts\n",
    "import datetime\n",
    "\n",
    "online_endpoint_name = \"endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"this is a sample online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"foo\": \"bar\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Create the endpoint\n",
    "\n",
    "Using the `MLClient` created earlier, we will now create the Endpoint in the workspace. This command will start the endpoint creation and return a confirmation response while the endpoint creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://endpoint-01090433141635.northeurope.inference.ml.azure.com/score', 'openapi_uri': 'https://endpoint-01090433141635.northeurope.inference.ml.azure.com/swagger.json', 'name': 'endpoint-01090433141635', 'description': 'this is a sample online endpoint', 'tags': {'foo': 'bar'}, 'properties': {'azureml.onlineendpointid': '/subscriptions/73fc0666-cbe3-4535-b3c6-83baeeaf94f5/resourcegroups/fhtw-solution-engineering/providers/microsoft.machinelearningservices/workspaces/fhtw-ml-23/onlineendpoints/endpoint-01090433141635', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/73fc0666-cbe3-4535-b3c6-83baeeaf94f5/providers/Microsoft.MachineLearningServices/locations/northeurope/mfeOperationsStatus/oe:9ff82a85-74dc-40ba-8b90-fea4cf264eb8:85b0ad75-5137-4f1f-bdfb-cf524d111448?api-version=2022-02-01-preview'}, 'id': '/subscriptions/73fc0666-cbe3-4535-b3c6-83baeeaf94f5/resourceGroups/fhtw-solution-engineering/providers/Microsoft.MachineLearningServices/workspaces/fhtw-ml-23/onlineEndpoints/endpoint-01090433141635', 'Resource__source_path': None, 'base_path': 'C:\\\\Users\\\\Moh\\\\Documents\\\\FH\\\\FHTW\\\\Slides\\\\WS21_SDC-MDS3\\\\laufendeLV\\\\EH3\\\\ml-deployment', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001FD411BD1C0>, 'auth_mode': 'key', 'location': 'northeurope', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x000001FD411ACEE0>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Configure online deployment\n",
    "\n",
    "A deployment is a set of resources required for hosting the model that does the actual inferencing. We will create a deployment for our endpoint using the `ManagedOnlineDeployment` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(path=\"./regression_model.pkl\")\n",
    "env = Environment(\n",
    "    conda_file=\"./conda.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    ")\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"./\", scoring_script=\"score.py\"\n",
    "    ),\n",
    "    instance_type=\"Standard_DS2_v2\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Create the deployment\n",
    "\n",
    "Using the `MLClient` created earlier, we will now create the deployment in the workspace. This command will start the deployment creation and return a confirmation response while the deployment creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint endpoint-01090433141635 exists\n",
      "\u001b[32mUploading ml-deployment (23.6 MBs): 100%|###########| 23604305/23604305 [00:09<00:00, 2448627.96it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "data_collector is not a known attribute of class <class 'azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedOnlineDeployment'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......"
     ]
    }
   ],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blue deployment takes 100 traffic\n",
    "endpoint.traffic = {\"blue\": 100}\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test the endpoint with sample data\n",
    "Using the `MLClient` created earlier, we will get a handle to the endpoint. The endpoint can be invoked using the `invoke` command with the following parameters:\n",
    "- `endpoint_name` - Name of the endpoint\n",
    "- `request_file` - File with request data\n",
    "- `deployment_name` - Name of the specific deployment to test in an endpoint\n",
    "\n",
    "We will send a sample request using a [json](./model-1/sample-request.json) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the blue deployment with some sample data\n",
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name=\"blue\",\n",
    "    request_file=\"../model-1/sample-request.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Managing endpoints and deployments\n",
    "\n",
    "## 6.1 Get details of the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the details for online endpoint\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "# existing traffic details\n",
    "print(endpoint.traffic)\n",
    "\n",
    "# Get the scoring URI\n",
    "print(endpoint.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Get the logs for the new deployment\n",
    "Get the logs for the green deployment and verify as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_deployments.get_logs(\n",
    "    name=\"blue\", endpoint_name=online_endpoint_name, lines=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Delete the endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Use an online endpoint to deploy your model, so you don't have to create and manage the underlying infrastructure"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
